{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "The idea is to analyze the tags provided on various problems that feature in programming contests to quantitatively see\n",
    "which type of problems are most common at various rating divisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codeforces\n",
    "\n",
    "For Codeforces, the common rating divisions are Div. 3, Div 2. and Div 1. with the problems ordered from least to most\n",
    "difficult. It would make sense to first identify the most recent contests of these types, find the problems they contain,\n",
    "and the corresponding tags. Then, we can visualize the distribution of the tags and see which are the most frequent,\n",
    "along with possible secondary statistics like which tags are the \"toughest\" i.e., correspond to most failed attmepts,\n",
    "which tags are the easiest and so on.\n",
    "\n",
    "Relevant APIs are -\n",
    "* `https://codeforces.com/api/contest.list`\n",
    "* `https://codeforces.com/api/problemset.problems`\n",
    "\n",
    "The first returns a list of all contests as a [`Contest`](https://codeforces.com/apiHelp/objects#Contest) object.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": 1854,\n",
    "    \"name\": \"Codeforces Round 889 (Div. 1)\",\n",
    "    \"type\": \"CF\",\n",
    "    \"phase\": \"BEFORE\",\n",
    "    \"frozen\": false,\n",
    "    \"durationSeconds\": 9000,\n",
    "    \"startTimeSeconds\": 1690641300,\n",
    "    \"relativeTimeSeconds\": -147153\n",
    "}\n",
    "```\n",
    "\n",
    "Relevant fields are only `id` and `name`. We need string-based heuristics for filtering the name to find the standard\n",
    "Codeforces rounds and their intended \"Div\"s.\n",
    "\n",
    "The problemset API returns a list of all problems as a [`Problem`]() object.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"contestId\": 1853,\n",
    "    \"index\": \"B\",\n",
    "    \"name\": \"Fibonaccharsis\",\n",
    "    \"type\": \"PROGRAMMING\",\n",
    "    \"points\": 1000.0,\n",
    "    \"rating\": 1200,\n",
    "    \"tags\": [\"binary search\", \"brute force\", \"math\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Relevant fields are `contestId`, to tie back to the contest and check whether it came from a regular CF Round, and which\n",
    "Div contest it came from. `rating` is also a useful feature to denote difficulty, and may be used skip the contest check\n",
    "entirely. `tags` is obviously the one we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "r = requests.get('https://codeforces.com/api/problemset.problems')\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Problem:\n",
    "    def __init__(self, name: str, rating: int, tags: List[str]):\n",
    "        self.name = name\n",
    "        self.rating = rating\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Problem(name={str(self.name)}, rating={str(self.rating)}, tags={str(self.tags)})'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return repr(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contestId': 1887, 'index': 'F', 'name': 'Minimum Segments', 'type': 'PROGRAMMING', 'points': 2750.0, 'tags': ['constructive algorithms']}\n"
     ]
    }
   ],
   "source": [
    "data = r.json()\n",
    "problems = data['result']['problems']\n",
    "print(problems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem(name=Minimum Segments, rating=nan, tags=['constructive algorithms'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "problems = [Problem(problem['name'], problem.get('rating', np.nan), problem.get('tags', [])) for problem in problems]\n",
    "print(problems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name  rating  \\\n",
      "0           Minimum Segments     NaN   \n",
      "1             Good Colorings     NaN   \n",
      "2                      Split     NaN   \n",
      "3              Minimum Array     NaN   \n",
      "4                Time Travel     NaN   \n",
      "...                      ...     ...   \n",
      "9002     The least round way  2000.0   \n",
      "9003                  Winner  1500.0   \n",
      "9004  Ancient Berland Circus  2100.0   \n",
      "9005             Spreadsheet  1600.0   \n",
      "9006          Theatre Square  1000.0   \n",
      "\n",
      "                                                   tags  \n",
      "0                             [constructive algorithms]  \n",
      "1     [binary search, constructive algorithms, graph...  \n",
      "2     [binary search, data structures, divide and co...  \n",
      "3     [binary search, brute force, constructive algo...  \n",
      "4               [binary search, graphs, shortest paths]  \n",
      "...                                                 ...  \n",
      "9002                                         [dp, math]  \n",
      "9003                          [hashing, implementation]  \n",
      "9004                                   [geometry, math]  \n",
      "9005                             [implementation, math]  \n",
      "9006                                             [math]  \n",
      "\n",
      "[9007 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "names = [problem.name for problem in problems]\n",
    "ratings = [problem.rating for problem in problems]\n",
    "tags = [problem.tags for problem in problems]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name': names,\n",
    "    'rating': ratings,\n",
    "    'tags': tags\n",
    "})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "{'math', 'implementation', 'interactive', 'flows', 'binary search', 'dsu', 'constructive algorithms', 'two pointers', 'number theory', 'meet-in-the-middle', 'string suffix structures', 'ternary search', 'sortings', 'divide and conquer', 'hashing', 'expression parsing', 'graph matchings', 'chinese remainder theorem', 'trees', 'schedules', 'fft', 'data structures', 'greedy', '*special', 'dp', 'brute force', 'shortest paths', 'geometry', 'dfs and similar', 'matrices', 'games', 'strings', 'combinatorics', '2-sat', 'graphs', 'probabilities', 'bitmasks'}\n"
     ]
    }
   ],
   "source": [
    "all_tags = set(tag for tags_list in df['tags'] for tag in tags_list)\n",
    "print(len(all_tags))\n",
    "print(all_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "tags_encoded = pd.DataFrame(mlb.fit_transform(df['tags']), columns=mlb.classes_, index=df.index)\n",
    "df = pd.concat([df, tags_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for tag in all_tags:\n",
    "        if row[tag] == 1:\n",
    "            result_data.append({'tag': tag, 'rating': row['rating']})\n",
    "\n",
    "result_df = pd.DataFrame(result_data)\n",
    "result_df = result_df.dropna()\n",
    "result_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Given this data, we want to gain insight into which tags are more common at certain rating ranges, such that competitors at those ranges have an idea of which problem tags will be useful to study if they want to progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"gEpqwr\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v3.2.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"gEpqwr\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"gEpqwr\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/akrish13/repos/cp-problem-tag-analysis/lets-plot-images/tag_distribution.png'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lets_plot as gg\n",
    "gg.LetsPlot.setup_html()\n",
    "\n",
    "p = gg.ggplot(result_df, aes(x='rating')) + \\\n",
    "    gg.geom_density(aes(color='tag', fill='tag'), alpha=.05,  \\\n",
    "                 tooltips=layer_tooltips().format('..count..', '.1f')  \\\n",
    "                                          .line('@tag') \\\n",
    "                                          .line('count|@..count..')) + \\\n",
    "    gg.ggsize(1920, 1080) + \\\n",
    "    gg.labs(x='Rating', y='Density', color='Tags', fill='Tags') + \\\n",
    "    gg.ggtitle(label='Tag Distribution by Rating on Codeforces', \\\n",
    "               subtitle='Density curves for each problem tag on Codeforces by its rating') + \\\n",
    "    gg.flavor_solarized_light() + \\\n",
    "    gg.theme(plot_title = element_text(hjust=0.5, face='bold'), plot_subtitle = element_text(hjust=0.5, color='#93a1a1'), \\\n",
    "             legend_title=element_text(hjust=0.5)) + \\\n",
    "    gg.theme(legend_text = element_text(size=10)) + \\\n",
    "    gg.guides(color = gg.guide_legend(ncol=2), fill = gg.guide_legend(ncol=2))\n",
    "\n",
    "gg.ggsave(p, 'tag_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeChef\n",
    "\n",
    "For CodeChef, we have two rating divisions of Div 2., and Div 1. There are long contests, short contests and Snacktime.\n",
    "For each of these, we can repeat the same process as in Codeforces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
